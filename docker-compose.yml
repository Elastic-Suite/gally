version: "3.4"

services:
  php:
    build:
      context: ./api
      target: gally_php
      args:
        COMPOSER_AUTH: ${COMPOSER_AUTH:-}
    depends_on:
      - database
      - search
      - redis
    restart: unless-stopped
    volumes:
      - php_socket:/var/run/php
    healthcheck:
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 120s
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-api-platform}:${POSTGRES_PASSWORD:-!ChangeMe!}@database:5432/${POSTGRES_DB:-api}?serverVersion=${POSTGRES_VERSION:-13}
      TRUSTED_PROXIES: ${TRUSTED_PROXIES:-127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16}
      TRUSTED_HOSTS: ^${SERVER_NAME:-example\.com|localhost}|caddy$$
      # MERCURE_URL: ${CADDY_MERCURE_URL:-http://caddy/.well-known/mercure}
      # MERCURE_PUBLIC_URL: https://${SERVER_NAME:-localhost}/.well-known/mercure
      # MERCURE_JWT_SECRET: ${CADDY_MERCURE_JWT_SECRET:-!ChangeMe!}

  pwa:
    build:
      context: ./front
      target: gally_pwa_prod
    environment:
      API_PLATFORM_CLIENT_GENERATOR_ENTRYPOINT: https://caddy
      NEXT_PUBLIC_ENTRYPOINT: https://caddy
    healthcheck:
      test: test $$(curl --connect-timeout 2 -s -o /dev/null -w ''%{http_code}'' http://localhost:3000) -eq 200
      interval: 10s
      timeout: 5s
      retries: 20

  caddy:
    build:
      context: api/
      target: gally_caddy
      args:
        COMPOSER_AUTH: ${COMPOSER_AUTH:-}
    depends_on:
      - php
      - pwa
    environment:
      PWA_UPSTREAM: pwa:3000
      # EXAMPLE_UPSTREAM: example:3001
      # SERVER_NAME: ${SERVER_NAME:-localhost, caddy:80}
      SERVER_NAME: ${SERVER_NAME:-localhost}
      # VARNISH_UPSTREAM: varnish:80
      VARNISH_UPSTREAM: varnish:80
      # MERCURE_PUBLISHER_JWT_KEY: ${CADDY_MERCURE_JWT_SECRET:-!ChangeMe!}
      # MERCURE_SUBSCRIBER_JWT_KEY: ${CADDY_MERCURE_JWT_SECRET:-!ChangeMe!}
      CADDY_TRUSTED_PROXIES: ${CADDY_TRUSTED_PROXIES:-127.0.0.0/8 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16}
    restart: unless-stopped
    volumes:
      - php_socket:/var/run/php
      - caddy_data:/data
      - caddy_config:/config
    ports:
      # HTTP
      - target: 80
        published: ${HTTP_PORT:-80}
        protocol: tcp
      # HTTPS
      - target: 443
        published: ${HTTPS_PORT:-443}
        protocol: tcp
      # HTTP/3
      - target: 443
        published: ${HTTP3_PORT:-443}
        protocol: udp
      - target: 8080
        published: 8080
        protocol: tcp

  varnish:
    # image: varnish:fresh-alpine
    image: varnish:7.2.1
    depends_on:
      - caddy
    restart: unless-stopped
    volumes:
      - './api/docker/varnish/default.vcl:/etc/varnish/default.vcl:ro,z'
    environment:
      - VARNISH_SIZE=512M
    #   - SERVERNAME=${SERVER_NAME:-localhost, caddy:80}
    # If http2 not already supported out of the box
    # command: "-p default_keep=300 -p feature=+http2"
    command: "-p default_keep=300 -p http_resp_hdr_len=65k"
    # restart: unless-stopped
    # ports: 
    #  - target: 80
    #    published: 8080
    #    protocol: tcp
       

  database:
    image: postgres:${POSTGRES_VERSION:-13}-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-api}
      # You should definitely change the password in production
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-!ChangeMe!}
      - POSTGRES_USER=${POSTGRES_USER:-api-platform}
    volumes:
      - db_data:/var/lib/postgresql/data:rw
      # you may use a bind-mounted host directory instead, so that it is harder to accidentally remove the volume and lose all your data!
      # - ./api/docker/db/data:/var/lib/postgresql/data:rw,z

  redis:
    image: docker.io/bitnami/redis:6.2
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
      # - REDIS_DISABLE_COMMANDS=FLUSHDB,FLUSHALL
    ports:
      - '6379:6379'
    volumes:
      - 'redis_data:/bitnami/redis/data'

  search:
    build:
      context: api/
      target: gally_opensearch2
    # restart: unless-stopped
    environment:
      - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_SECURITY_PLUGIN=true"       # Disable security plugin
      - cluster.name=os-docker-cluster       # Search cluster name
      - cluster.routing.allocation.disk.threshold_enabled=false     # Avoid ES going read-only because low disk space availability
      - cluster.initial_cluster_manager_nodes=opensearch-node-data # Nodes eligible to serve as cluster manager
      - node.name=opensearch-node-data       # Name the node that will run in this container
      - bootstrap.memory_lock=true           # Disable JVM heap memory swapping
      - discovery.seed_hosts=search          # Nodes to look for when discovering the cluster
      - plugins.ml_commons.allow_registering_model_via_url=true
      - plugins.ml_commons.native_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
      - plugins.ml_commons.jvm_heap_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
    volumes:
      - os2_data:/usr/share/opensearch/data:rw
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
    healthcheck:
      test: test $$(curl --write-out %{http_code} --fail --silent --output /dev/null http://localhost:9200/_cluster/health?wait_for_status=green&timeout=5s) -eq 200
      interval: 10s
      timeout: 5s
      retries: 20
      
  search-ml:
    build:
      context: api/
      target: gally_opensearch2
    # restart: unless-stopped
    environment:
      - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_SECURITY_PLUGIN=true"       # Disable security plugin
      - cluster.name=os-docker-cluster       # Search cluster name
      - cluster.routing.allocation.disk.threshold_enabled=false # Avoid ES going read-only because low disk space availability
      - cluster.initial_cluster_manager_nodes=opensearch-node-data # Nodes eligible to serve as cluster manager
      - node.name=opensearch-node-ml         # Name the node that will run in this container
      - node.roles=ml                        # Define this node as an ml node
      - bootstrap.memory_lock=true           # Disable JVM heap memory swapping
      - discovery.seed_hosts=search          # Nodes to look for when discovering the cluster
      - plugins.ml_commons.allow_registering_model_via_url=true
      - plugins.ml_commons.native_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
      - plugins.ml_commons.jvm_heap_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - os2_ml_data:/usr/share/opensearch/data:rw
    healthcheck:
      test: test $$(curl --write-out %{http_code} --fail --silent --output /dev/null http://localhost:9200/_cluster/health?wait_for_status=green&timeout=5s) -eq 200
      interval: 10s
      timeout: 5s
      retries: 20

# Mercure is installed as a Caddy module, prevent the Flex recipe from installing another service
###> symfony/mercure-bundle ###
###< symfony/mercure-bundle ###

volumes:
  php_socket:
  caddy_data:
  caddy_config:
###> doctrine/doctrine-bundle ###
  db_data:
###< doctrine/doctrine-bundle ###
  os2_data:
  os2_ml_data:
###> symfony/mercure-bundle ###
###< symfony/mercure-bundle ###
  redis_data:
    driver: local
