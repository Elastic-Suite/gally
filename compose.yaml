services:
  proxy:
    build:
      context: ./docker/proxy
    ports:
      - "443:443"
    volumes:
      - ./docker/certs:/etc/nginx/certs:ro #todo check how to manage ssl on prod !
    depends_on:
      - varnish
    environment:
      - API_SERVER_NAME=${API_SERVER_NAME:-api.gally.localhost}
      - PWA_SERVER_NAME=${PWA_SERVER_NAME:-gally.localhost}
      - BACKEND_UPSTREAM=varnish:80

  varnish:
    build:
      context: ./docker/varnish
    depends_on:
      - router
    environment:
      - BACKEND_HOST=router
      - BACKEND_PORT=80
      - PHP_UPSTREAM=php
      - VARNISH_SIZE=512M

  router:
    build:
      context: ./docker/router
    volumes:
      - php_static_files:/app/public:ro
    depends_on:
      - php
      - pwa 
    environment:
      - API_SERVER_NAME=${API_SERVER_NAME:-api.gally.localhost}
      - API_UPSTREAM=${API_UPSTREAM:-php:9000}
      - PWA_SERVER_NAME=${PWA_SERVER_NAME:-gally.localhost}
      - PWA_UPSTREAM=${PWA_UPSTREAM:-pwa:3000}
  
  php:
    build:
      context: ./api
      target: gally_php_prod
      args:
        COMPOSER_AUTH: ${COMPOSER_AUTH:-}
    volumes:
      - php_static_files:/app/public:rw
    depends_on: 
      - database
      - search
      - redis
    environment:
      - APP_ENV=${APP_ENV:-prod}
      - APP_SECRET=${APP_SECRET:-!ChangeMe!}
      - PWA_UPSTREAM=pwa:3000
      - SERVER_NAME=${API_SERVER_NAME:-api.gally.localhost}, php:80
      - TRUSTED_PROXIES=${TRUSTED_PROXIES:-127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16}
      - TRUSTED_HOSTS=${TRUSTED_HOSTS:-^${API_SERVER_NAME:-example\.com|api.gally.localhost}|localhost|php$$}
      - CORS_ALLOW_ORIGIN=^https?://${PWA_SERVER_NAME:-gally.localhost}$
      - DATABASE_URL=postgresql://${POSTGRES_USER:-app}:${POSTGRES_PASSWORD:-!ChangeMe!}@database:5432/${POSTGRES_DB:-app}?serverVersion=${POSTGRES_VERSION:-16}&charset=${POSTGRES_CHARSET:-utf8}
      - GALLY_CATALOG_MEDIA_URL=${GALLY_CATALOG_MEDIA_URL:-https://gally.localhost/media/catalog/product/}

  pwa:
    build:
      context: ./front
      target: gally_pwa_prod
      args:
        - NEXT_PUBLIC_ENTRYPOINT=${PWA_SERVER_NAME:-gally.localhost} # Why this .. todo upgrade
        - NEXT_PUBLIC_API_URL=https://${API_SERVER_NAME:-api.gally.localhost}
    environment:
      # old value
#      - NEXT_PUBLIC_ENTRYPOINT=http://php # Why this .. todo upgrade
      - NEXT_PUBLIC_ENTRYPOINT=${PWA_SERVER_NAME:-gally.localhost} # Why this .. todo upgrade
      - NEXT_PUBLIC_API_URL=https://${API_SERVER_NAME:-api.gally.localhost}
    healthcheck:
      test: test $$(curl --connect-timeout 2 -s -o /dev/null -w ''%{http_code}'' http://localhost:3000) -eq 200
      interval: 10s
      timeout: 5s
      retries: 20
  
  ###> doctrine/doctrine-bundle ###
  database:
    image: postgres:${POSTGRES_VERSION:-16}-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-app}
      # You should definitely change the password in production
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-!ChangeMe!}
      - POSTGRES_USER=${POSTGRES_USER:-app}
    volumes:
      - db_data:/var/lib/postgresql/data
      # you may use a bind-mounted host directory instead, so that it is harder to accidentally remove the volume and lose all your data!
      # - ./api/docker/db/data:/var/lib/postgresql/data
  ###< doctrine/doctrine-bundle ###

  redis:
    image: docker.io/bitnami/redis:6.2
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
      # - REDIS_DISABLE_COMMANDS=FLUSHDB,FLUSHALL
    volumes:
      - 'redis_data:/bitnami/redis/data'

  search:
    build:
      context: docker/search/
      target: gally_opensearch2
    # restart: unless-stopped
    environment:
      - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_SECURITY_PLUGIN=true"       # Disable security plugin todo upgrade : manage security
      - cluster.name=os-docker-cluster       # Search cluster name
      - cluster.routing.allocation.disk.threshold_enabled=false     # Avoid ES going read-only because low disk space availability
      - cluster.initial_cluster_manager_nodes=opensearch-node-data # Nodes eligible to serve as cluster manager
      - node.name=opensearch-node-data       # Name the node that will run in this container
      - bootstrap.memory_lock=true           # Disable JVM heap memory swapping
      - discovery.seed_hosts=search          # Nodes to look for when discovering the cluster
      - plugins.ml_commons.allow_registering_model_via_url=true
      - plugins.ml_commons.native_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
      - plugins.ml_commons.jvm_heap_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
    volumes:
      - os2_data:/usr/share/opensearch/data:rw
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
    healthcheck:
      test: test $$(curl --write-out %{http_code} --fail --silent --output /dev/null http://localhost:9200/_cluster/health?wait_for_status=green&timeout=5s) -eq 200
      interval: 10s
      timeout: 5s
      retries: 20

  search-ml:
    build:
      context: docker/search/
      target: gally_opensearch2
    # restart: unless-stopped
    environment:
      - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_SECURITY_PLUGIN=true"       # Disable security plugin
      - cluster.name=os-docker-cluster       # Search cluster name
      - cluster.routing.allocation.disk.threshold_enabled=false # Avoid ES going read-only because low disk space availability
      - cluster.initial_cluster_manager_nodes=opensearch-node-data # Nodes eligible to serve as cluster manager
      - node.name=opensearch-node-ml         # Name the node that will run in this container
      - node.roles=ml                        # Define this node as an ml node
      - bootstrap.memory_lock=true           # Disable JVM heap memory swapping
      - discovery.seed_hosts=search          # Nodes to look for when discovering the cluster
      - plugins.ml_commons.allow_registering_model_via_url=true
      - plugins.ml_commons.native_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
      - plugins.ml_commons.jvm_heap_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - os2_ml_data:/usr/share/opensearch/data:rw
    healthcheck:
      test: test $$(curl --write-out %{http_code} --fail --silent --output /dev/null http://localhost:9200/_cluster/health?wait_for_status=green&timeout=5s) -eq 200
      interval: 10s
      timeout: 5s
      retries: 20

volumes:
  php_static_files:
###> doctrine/doctrine-bundle ###
  db_data:
###< doctrine/doctrine-bundle ###
  os2_data:
  os2_ml_data:
  redis_data:
    driver: local
