services:
  proxy:
    build:
      context: ./docker/proxy
    ports:
      - "443:443"
    volumes:
      - ./docker/certs:/etc/nginx/certs:ro #todo check how to manage ssl on prod !
    depends_on:
      - varnish
    environment:
      - API_SERVER_NAME=${API_SERVER_NAME:-api.gally.localhost}
      - PWA_SERVER_NAME=${PWA_SERVER_NAME:-gally.localhost}
      - BACKEND_UPSTREAM=varnish:80

  varnish:
    build:
      context: ./docker/varnish
    depends_on:
      - router
    environment:
      - BACKEND_HOST=router
      - BACKEND_PORT=80
      - PHP_UPSTREAM=php
      - VARNISH_SIZE=512M

  router:
    build:
      context: ./docker/router
    volumes:
      - php_static_files:/app/public:ro
    depends_on:
      - php
      - pwa 
    environment:
      - API_SERVER_NAME=${API_SERVER_NAME:-api.gally.localhost}
      - API_UPSTREAM=${API_UPSTREAM:-php:9000}
      - PWA_SERVER_NAME=${PWA_SERVER_NAME:-gally.localhost}
      - PWA_UPSTREAM=${PWA_UPSTREAM:-pwa:3000}
  
  php:
    build:
      context: ./api
      target: gally_php_prod
      args:
        COMPOSER_AUTH: ${COMPOSER_AUTH:-}
    volumes:
      - php_static_files:/app/public:rw
    depends_on: 
      - database
      - search
      - redis
    environment:
      - APP_ENV=${APP_ENV:-prod}
      - APP_SECRET=${APP_SECRET:-!ChangeMe!}
      - PWA_UPSTREAM=pwa:3000
      - SERVER_NAME=${API_SERVER_NAME:-api.gally.localhost}, php:80
      - TRUSTED_PROXIES=${TRUSTED_PROXIES:-127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16}
      - TRUSTED_HOSTS=${TRUSTED_HOSTS:-^${API_SERVER_NAME:-example\.com|api.gally.localhost}|php$$}
      - CORS_ALLOW_ORIGIN=^https?://${PWA_SERVER_NAME:-gally.localhost}$
      - DATABASE_URL=postgresql://${POSTGRES_USER:-app}:${POSTGRES_PASSWORD:-!ChangeMe!}@database:5432/${POSTGRES_DB:-app}?serverVersion=${POSTGRES_VERSION:-16}&charset=${POSTGRES_CHARSET:-utf8}
      - GALLY_CATALOG_MEDIA_URL=${GALLY_CATALOG_MEDIA_URL:-https://gally.localhost/media/catalog/product/}
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL:-http://search:9200/}


  pwa:
    build:
      context: ./front
      target: gally_pwa_prod
#      args:
#        - NEXT_PUBLIC_ENTRYPOINT=${PWA_SERVER_NAME:-gally.localhost} # Why this .. todo upgrade
#        - NEXT_PUBLIC_API_URL=https://${API_SERVER_NAME:-api.gally.localhost}
    environment:
      # old value
#      - NEXT_PUBLIC_ENTRYPOINT=http://php # Why this .. todo upgrade
      - NEXT_PUBLIC_ENTRYPOINT=${PWA_SERVER_NAME:-gally.localhost} # Why this .. todo upgrade
      - NEXT_PUBLIC_API_URL=https://${API_SERVER_NAME:-api.gally.localhost}
    healthcheck:
      test: test $$(curl --connect-timeout 2 -s -o /dev/null -w ''%{http_code}'' http://localhost:3000) -eq 200
      interval: 10s
      timeout: 5s
      retries: 20
  
  ###> doctrine/doctrine-bundle ###
  database:
    image: postgres:${POSTGRES_VERSION:-16}-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-app}
      # You should definitely change the password in production
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-!ChangeMe!}
      - POSTGRES_USER=${POSTGRES_USER:-app}
    volumes:
      - db_data:/var/lib/postgresql/data
      # you may use a bind-mounted host directory instead, so that it is harder to accidentally remove the volume and lose all your data!
      # - ./api/docker/db/data:/var/lib/postgresql/data
  ###< doctrine/doctrine-bundle ###

  redis:
    image: docker.io/bitnami/redis:6.2
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
      # - REDIS_DISABLE_COMMANDS=FLUSHDB,FLUSHALL
    volumes:
      - 'redis_data:/bitnami/redis/data'

  search:
    build:
      context: docker/search/
      target: gally_opensearch2
    # restart: unless-stopped
    environment:
      - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_SECURITY_PLUGIN=true"       # Disable security plugin todo upgrade : manage security
      - cluster.name=os-docker-cluster       # Search cluster name
      - cluster.routing.allocation.disk.threshold_enabled=false     # Avoid ES going read-only because low disk space availability
#      - cluster.initial_cluster_manager_nodes=opensearch-node-data # Nodes eligible to serve as cluster manager
      - node.name=opensearch-node-data       # Name the node that will run in this container
      - bootstrap.memory_lock=true           # Disable JVM heap memory swapping
#      - discovery.seed_hosts=search          # Nodes to look for when discovering the cluster
      - plugins.ml_commons.allow_registering_model_via_url=true
      - plugins.ml_commons.native_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
      - plugins.ml_commons.jvm_heap_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
      - discovery.type=single-node
      - plugins.ml_commons.only_run_on_ml_node=false
    volumes:
      - os2_data:/usr/share/opensearch/data:rw
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
    healthcheck:
      test: test $$(curl --write-out %{http_code} --fail --silent --output /dev/null http://localhost:9200/_cluster/health?wait_for_status=green&timeout=5s) -eq 200
      interval: 10s
      timeout: 5s
      retries: 20

#  search-ml:
#    build:
#      context: docker/search/
#      target: gally_opensearch2
#    # restart: unless-stopped
#    environment:
#      - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g" # Set min and max JVM heap sizes to at least 50% of system RAM
#      - "DISABLE_SECURITY_PLUGIN=true"       # Disable security plugin
#      - cluster.name=os-docker-cluster       # Search cluster name
#      - cluster.routing.allocation.disk.threshold_enabled=false # Avoid ES going read-only because low disk space availability
#      - cluster.initial_cluster_manager_nodes=opensearch-node-data # Nodes eligible to serve as cluster manager
#      - node.name=opensearch-node-ml         # Name the node that will run in this container
#      - node.roles=ml                        # Define this node as an ml node
#      - bootstrap.memory_lock=true           # Disable JVM heap memory swapping
#      - discovery.seed_hosts=search          # Nodes to look for when discovering the cluster
#      - plugins.ml_commons.allow_registering_model_via_url=true
#      - plugins.ml_commons.native_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
#      - plugins.ml_commons.jvm_heap_memory_threshold=100 # Prevent memory issue after multiple deploy (https://github.com/opensearch-project/ml-commons/issues/2308)
#    ulimits:
#      memlock:
#        soft: -1
#        hard: -1
#    volumes:
#      - os2_ml_data:/usr/share/opensearch/data:rw
#    healthcheck:
#      test: test $$(curl --write-out %{http_code} --fail --silent --output /dev/null http://localhost:9200/_cluster/health?wait_for_status=green&timeout=5s) -eq 200
#      interval: 10s
#      timeout: 5s
#      retries: 20

volumes:
  php_static_files:
###> doctrine/doctrine-bundle ###
  db_data:
###< doctrine/doctrine-bundle ###
  os2_data:
  os2_ml_data:
  redis_data:
    driver: local
